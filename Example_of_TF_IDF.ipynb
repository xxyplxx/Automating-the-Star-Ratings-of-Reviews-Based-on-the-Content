{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Example of TF-IDF.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFzKFXsH6DbV",
        "outputId": "c4077796-12ac-4752-b966-58af0aa518a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import math\n",
        "import string \n",
        "import nltk.stem\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "text_1 = \"Sexiest car\"\n",
        "text_2 = \"For a pretty affordable price.\"\n",
        "text_3 = \"back seat is very small\"\n",
        "\n",
        "punctuation_map = dict((ord(char), None) for char in string.punctuation)  \n",
        "s = nltk.stem.SnowballStemmer('english')  \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def stem_count(text):\n",
        "    l_text = text.lower()    \n",
        "    without_punctuation = l_text.translate(punctuation_map)   \n",
        "    tokens = nltk.word_tokenize(without_punctuation)       \n",
        "    without_stopwords = [w for w in tokens if not w in stopwords.words('english')]   \n",
        "    cleaned_text = [] \n",
        "    for i in range(len(without_stopwords)):\n",
        "        cleaned_text.append(s.stem(without_stopwords[i]))    \n",
        "    count = Counter(cleaned_text)                 \n",
        "    return count"
      ],
      "metadata": {
        "id": "I67thOqR6VgW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def D_con(word, count_list): \n",
        "    D_con = 0\n",
        "    for count in count_list:\n",
        "        if word in count:\n",
        "            D_con += 1\n",
        "    return D_con\n",
        "def tf(word, count): \n",
        "    return count[word] / sum(count.values())\n",
        "def idf(word, count_list): \n",
        "    return math.log(len(count_list)) / (1 + D_con(word, count_list))\n",
        "def tfidf(word, count, count_list):\n",
        "    return tf(word, count) * idf(word, count_list)"
      ],
      "metadata": {
        "id": "qslHwlHR6W8m"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [text_1, text_2, text_3] \n",
        "count_list = [] \n",
        "for text in texts: \n",
        "    count_list.append(stem_count(text))      \n",
        "for i in range(len(count_list)):\n",
        "    print('For document {}'.format(i+1))\n",
        "    tf_idf = {}\n",
        "    for word in count_list[i]:\n",
        "        tf_idf[word] = tfidf(word, count_list[i], count_list)\n",
        "    sort = sorted(tf_idf.items(), key = lambda x: x[1], reverse=True) \n",
        "    for word, tf_idf in sort[:7]: \n",
        "        print(\"\\tWord: {} : {}\".format(word, round(tf_idf, 6)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scMBh4XR6YWL",
        "outputId": "fbf84aa4-9919-4db3-f210-208757fbe915"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For document 1\n",
            "\tWord: sexiest : 0.274653\n",
            "\tWord: car : 0.274653\n",
            "For document 2\n",
            "\tWord: pretti : 0.183102\n",
            "\tWord: afford : 0.183102\n",
            "\tWord: price : 0.183102\n",
            "For document 3\n",
            "\tWord: back : 0.183102\n",
            "\tWord: seat : 0.183102\n",
            "\tWord: small : 0.183102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOZimxI-7NsR",
        "outputId": "4668d804-b210-4f35-e0e0-eb2e3f463374"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Counter({'car': 1, 'sexiest': 1}),\n",
              " Counter({'afford': 1, 'pretti': 1, 'price': 1}),\n",
              " Counter({'back': 1, 'seat': 1, 'small': 1})]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}